"""Agente especializado em Recursos Humanos - VERSÃƒO ASSÃNCRONA
Baseado no BaseSubagent mas com suporte completo a operaÃ§Ãµes assÃ­ncronas"""

from __future__ import annotations

from textwrap import dedent
from typing import Optional
import asyncio

from subagents.base_subagent import SubagentConfig
from dal.postgres_dal_async import PostgresDALAsync
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from core.config import config

PROMPT_TEMPLATE = dedent(
    """
    VocÃª Ã© Ana, uma especialista em Recursos Humanos. VocÃª faz parte do ecossistema Neoson e orienta colaboradores internos com dÃºvidas relacionadas Ã  Ã¡rea de RH.

    IMPORTANTE: Baseie suas respostas SOMENTE nas informaÃ§Ãµes do contexto fornecido abaixo.

    DIRETRIZES DE RESPOSTA:
    - Adote tom profissional, cordial e acessÃ­vel
    - Explique polÃ­ticas e procedimentos de forma clara e compreensÃ­vel
    - Mencione histÃ³rico prÃ©vio quando aplicÃ¡vel
    - Varie saudaÃ§Ãµes e evite repetiÃ§Ã£o excessiva
    - Utilize emojis moderadamente para humanizar a conversa (opcional)
    - Alerte quando o conteÃºdo parecer desatualizado ou incompleto

    CASOS ESPECIAIS:
    - Sem informaÃ§Ã£o relevante: "NÃ£o localizei essa informaÃ§Ã£o na base atual. Recomendo acionar o time de RH diretamente ou registrar um ticket conforme o procedimento padrÃ£o."
    - InformaÃ§Ã£o restrita: "Essa informaÃ§Ã£o Ã© confidencial. Solicite autorizaÃ§Ã£o formal Ã  lideranÃ§a de RH ou registre um ticket justificando a necessidade."
    - ConteÃºdo possivelmente obsoleto: "âš ï¸ AtenÃ§Ã£o: essa informaÃ§Ã£o pode estar desatualizada. Valide com o time de RH antes de seguir."

    {historico_conversa}CONTEXTO DISPONÃVEL:
    {contexto}

    PERGUNTA DO COLABORADOR:
    {pergunta}

    RESPOSTA (considere polÃ­ticas de RH e histÃ³rico ao responder):
    """
).strip()

KEYWORDS = [
    'rh', 'recursos humanos', 'fÃ©rias', 'benefÃ­cios', 'salÃ¡rio', 'contrato',
    'home office', 'folga', 'falta', 'atestado', 'demissÃ£o', 'contrataÃ§Ã£o',
    'polÃ­tica', 'procedimento', 'vale refeiÃ§Ã£o', 'vale transporte', 'plr',
    'dÃ©cimo terceiro', 'licenÃ§a', 'maternidade', 'paternidade', 'treinamento',
    'desenvolvimento', 'carreira', 'avaliaÃ§Ã£o', 'desempenho', 'ponto',
    'horÃ¡rio', 'escala', 'banco de horas', 'overtime', 'extra'
]


class AgenteRHAsync:
    """Agente especializado em Recursos Humanos com operaÃ§Ãµes ASSÃNCRONAS"""

    def __init__(self, *, debug: bool = False) -> None:
        self.config = SubagentConfig(
            identifier="rh",
            name="Ana",
            specialty="Recursos Humanos",
            description="Especialista em recursos humanos, polÃ­ticas de pessoal, benefÃ­cios e procedimentos internos",
            keywords=KEYWORDS,
            table_name="knowledge_hr",
            prompt_template=PROMPT_TEMPLATE,
            debug=debug
        )
        
        # Inicializar componentes assÃ­ncronos
        self.dal_async = PostgresDALAsync()
        self.llm = None
        self.embeddings = None
        self.memoria_conversas = {}
        
        # Inicializar LLM e embeddings
        self._inicializar_llm()
    
    def _inicializar_llm(self):
        """Inicializa LLM e embeddings"""
        api_key = config.openai.api_key
        
        self.llm = ChatOpenAI(
            api_key=api_key,
            model=config.openai.chat_model,
            temperature=0.3,
            max_tokens=800
        )
        
        self.embeddings = OpenAIEmbeddings(
            api_key=api_key,
            model=config.openai.embedding_model
        )
    
    async def processar_async(self, pergunta: str, user_profile: dict) -> str:
        """Processa pergunta de forma ASSÃNCRONA"""
        try:
            if self.config.debug:
                print(f"ğŸ”„ [{self.config.name}] Processando pergunta (ASYNC): '{pergunta[:50]}...'")
            
            # Conectar ao banco de forma assÃ­ncrona
            await self.dal_async.connect()
            
            # Gerar embedding da pergunta
            query_embedding = await asyncio.to_thread(
                self.embeddings.embed_query, 
                pergunta
            )
            
            # Buscar contexto relevante de forma assÃ­ncrona
            search_result = await self.dal_async.search_vectors_async(
                table_name=self.config.table_name,
                query_vector=query_embedding,
                limit=5,
                similarity_threshold=0.5
            )
            
            if self.config.debug:
                print(f"ğŸ“Š [{self.config.name}] Encontrados {len(search_result.documents)} documentos relevantes")
            
            # Preparar contexto
            contexto_str = self._preparar_contexto(search_result.documents)
            
            # Preparar histÃ³rico
            usuario_id = f"{user_profile.get('Nome', 'usuario')}_{user_profile.get('Departamento', 'geral')}"
            historico_str = self._preparar_historico(usuario_id)
            
            # Preparar prompt
            prompt_final = self.config.prompt_template.format(
                historico_conversa=historico_str,
                contexto=contexto_str,
                pergunta=pergunta
            )
            
            # Gerar resposta de forma assÃ­ncrona
            if self.config.debug:
                print(f"ğŸ¤– [{self.config.name}] Gerando resposta com LLM (ASYNC)...")
            
            resposta = await asyncio.to_thread(
                self.llm.invoke,
                prompt_final
            )
            
            resposta_texto = resposta.content if hasattr(resposta, 'content') else str(resposta)
            
            # Armazenar na memÃ³ria
            self._adicionar_memoria(usuario_id, pergunta, resposta_texto)
            
            if self.config.debug:
                print(f"âœ… [{self.config.name}] Resposta gerada com {len(resposta_texto)} caracteres")
            
            return resposta_texto
            
        except Exception as e:
            error_msg = f"âŒ Erro ao processar pergunta (Agente {self.config.name}): {str(e)}"
            print(error_msg)
            return f"Desculpe, encontrei um erro ao processar sua pergunta sobre RH. Por favor, tente novamente."
        
        finally:
            await self.dal_async.disconnect()
    
    def _preparar_contexto(self, documents: list) -> str:
        """Prepara o contexto a partir dos documentos recuperados"""
        if not documents:
            return "Nenhum documento relevante encontrado na base de conhecimento."
        
        contexto_parts = []
        for i, doc in enumerate(documents, 1):
            conteudo = doc.get('conteudo', doc.get('content', ''))
            metadata_str = doc.get('metadata', {})
            
            contexto_parts.append(f"[Documento {i}]")
            if metadata_str:
                contexto_parts.append(f"Metadados: {metadata_str}")
            contexto_parts.append(conteudo)
            contexto_parts.append("")  # Linha em branco
        
        return "\n".join(contexto_parts)
    
    def _preparar_historico(self, usuario_id: str) -> str:
        """Prepara o histÃ³rico de conversas do usuÃ¡rio"""
        if usuario_id not in self.memoria_conversas:
            return ""
        
        historico = self.memoria_conversas[usuario_id]
        if not historico:
            return ""
        
        # Pegar as Ãºltimas 3 interaÃ§Ãµes
        ultimas_interacoes = historico[-3:]
        
        historico_parts = ["HISTÃ“RICO RECENTE DA CONVERSA:"]
        for i, (perg, resp) in enumerate(ultimas_interacoes, 1):
            historico_parts.append(f"\nInteraÃ§Ã£o {i}:")
            historico_parts.append(f"UsuÃ¡rio: {perg}")
            historico_parts.append(f"Ana: {resp[:200]}...")  # Resumir resposta
        
        historico_parts.append("\n")
        return "\n".join(historico_parts)
    
    def _adicionar_memoria(self, usuario_id: str, pergunta: str, resposta: str):
        """Adiciona interaÃ§Ã£o Ã  memÃ³ria"""
        if usuario_id not in self.memoria_conversas:
            self.memoria_conversas[usuario_id] = []
        
        self.memoria_conversas[usuario_id].append((pergunta, resposta))
        
        # Manter apenas as Ãºltimas 10 interaÃ§Ãµes
        if len(self.memoria_conversas[usuario_id]) > 10:
            self.memoria_conversas[usuario_id] = self.memoria_conversas[usuario_id][-10:]
    
    def obter_info_agente(self) -> dict:
        """Retorna informaÃ§Ãµes do agente"""
        return {
            'identifier': self.config.identifier,
            'name': self.config.name,
            'specialty': self.config.specialty,
            'descricao': self.config.description,
            'keywords': self.config.keywords,
            'table_name': self.config.table_name,
            'tipo': 'async',
            'memoria_usuarios': len(self.memoria_conversas)
        }


def criar_agente_rh_async(*, debug: bool = False) -> Optional[AgenteRHAsync]:
    """Factory function para criar o agente de RH assÃ­ncrono"""
    try:
        if debug:
            print("ğŸ­ Criando agente RH assÃ­ncrono...")

        agente = AgenteRHAsync(debug=debug)

        if debug:
            print(f"âœ… Agente RH Async criado: {agente.config.name}")
            print(f"ğŸ“Š Keywords: {len(agente.config.keywords)} termos")
            print(f"ğŸ—„ï¸ Tabela: {agente.config.table_name}")

        return agente

    except Exception as e:
        if debug:
            print(f"âŒ Erro ao criar agente RH async: {e}")
        return None


if __name__ == "__main__":
    import asyncio
    
    async def teste_agente():
        """Teste do agente RH assÃ­ncrono"""
        print("ğŸ§ª Testando Agente RH Async...")

        agente = criar_agente_rh_async(debug=True)

        if agente:
            print("âœ… Agente RH Async inicializado com sucesso!")

            # Perfil de teste
            perfil_teste = {
                "Nome": "JoÃ£o Silva",
                "Cargo": "Analista",
                "Departamento": "RH",
                "Nivel_Hierarquico": 3,
                "Geografia": "BR",
                "Projetos": ["Projeto X"]
            }

            # Teste de pergunta
            pergunta_teste = "Qual Ã© a polÃ­tica de fÃ©rias da empresa?"

            print(f"\nğŸ¯ Pergunta de teste: {pergunta_teste}")
            resposta = await agente.processar_async(pergunta_teste, perfil_teste)
            print(f"ğŸ¤– Resposta: {resposta[:200]}...")

            print("\nğŸ“Š InformaÃ§Ãµes do agente:")
            info = agente.obter_info_agente()
            for chave, valor in info.items():
                print(f"  {chave}: {valor}")
        else:
            print("âŒ Falha na inicializaÃ§Ã£o do agente RH Async")
    
    asyncio.run(teste_agente())
