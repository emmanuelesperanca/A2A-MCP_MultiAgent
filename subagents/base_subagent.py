"""Infraestrutura compartilhada para cria√ß√£o de subagentes Neoson."""

from __future__ import annotations

import os
import warnings
from dataclasses import dataclass, field
from datetime import date, datetime
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

from postgres_vector_store import PostgresVectorStore

warnings.simplefilter(action="ignore", category=FutureWarning)


@dataclass
class SubagentConfig:
    """Configura√ß√£o declarativa para instanciar um subagente."""

    identifier: str
    name: str
    specialty: str
    description: str
    keywords: List[str]
    prompt_template: str
    table_name: Optional[str] = None
    table_env_var: Optional[str] = None
    database_env_var: Optional[str] = None
    llm_model: str = "gpt-4o-mini"
    llm_temperature: float = 0.3
    llm_max_tokens: int = 1000
    embedding_model: str = "text-embedding-3-small"
    error_message: str = (
        "Ops! Tive um problema t√©cnico aqui. Que tal tentar novamente em instantes ou acionar o suporte?"
    )
    debug: bool = False
    # Configura√ß√µes MCP
    enable_mcp_tools: bool = False
    mcp_tools_category: Optional[str] = None
    mcp_tool_server_url: Optional[str] = None
    # Configura√ß√µes A2A
    enable_a2a: bool = False
    delegation_rules: List = field(default_factory=list)
    max_delegation_depth: int = 2

    def __post_init__(self) -> None:
        identifier_clean = self.identifier.strip()
        if not identifier_clean:
            raise ValueError("identifier n√£o pode ser vazio")
        self.identifier = identifier_clean
        self.error_message = self.error_message.strip()

        default_table = f"knowledge_{identifier_clean.lower()}"
        self.table_name = self.table_name or default_table

        upper_identifier = identifier_clean.upper()
        default_table_env = f"KNOWLEDGE_{upper_identifier}_TABLE"
        default_db_env = f"KNOWLEDGE_{upper_identifier}_DATABASE_URL"

        self.table_env_var = self.table_env_var or default_table_env
        self.database_env_var = self.database_env_var or default_db_env
        
        # Se MCP est√° habilitado mas categoria n√£o definida, usa o identifier
        if self.enable_mcp_tools and not self.mcp_tools_category:
            self.mcp_tools_category = identifier_clean.lower()


class BaseSubagent:
    """Agente base parametrizado por prompt e fonte de conhecimento."""

    def __init__(self, config: SubagentConfig) -> None:
        self.config = config
        self.llm: Optional[ChatOpenAI] = None
        self.embeddings: Optional[OpenAIEmbeddings] = None
        self.vector_store: Optional[PostgresVectorStore] = None
        self.memoria_conversas: Dict[str, List[Dict[str, Any]]] = {}
        self.db_dsn: Optional[str] = None
        self.table_name: str = config.table_name
        # MCP Components
        self.mcp_client = None
        self.available_tools: List = []
        # A2A Components
        self.agent_registry = None
        self.current_session = None
        self.last_sources_used: List[str] = []
        self.last_tools_used: List[str] = []

    # ------------------------------------------------------------------
    # Helpers de logging
    # ------------------------------------------------------------------
    def _log(self, mensagem: str) -> None:
        if self.config.debug:
            print(mensagem)

    # ------------------------------------------------------------------
    # Carregamento e inicializa√ß√£o
    # ------------------------------------------------------------------
    def carregar_configuracoes_e_dados(self) -> str:
        self._log(f"--- üîÑ Carregando configura√ß√µes do agente {self.config.name}... ---")
        load_dotenv()

        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("Chave da API OPENAI_API_KEY n√£o encontrada nas vari√°veis de ambiente")

        db_env = self.config.database_env_var
        table_env = self.config.table_env_var

        self.db_dsn = os.getenv(db_env or "DATABASE_URL") or os.getenv("DATABASE_URL")
        if not self.db_dsn:
            raise ValueError(
                f"Vari√°vel de ambiente DATABASE_URL ou {db_env} n√£o configurada para o agente {self.config.identifier}."
            )

        self.table_name = os.getenv(table_env, self.config.table_name)
        self._log(f"‚úÖ Fonte de conhecimento configurada: tabela '{self.table_name}'.")
        return api_key

    def inicializar_modelos(self, api_key: str) -> None:
        self._log(f"--- ü§ñ Inicializando modelos OpenAI para {self.config.specialty}... ---")
        self.llm = ChatOpenAI(
            api_key=api_key,
            model=self.config.llm_model,
            temperature=self.config.llm_temperature,
            max_tokens=self.config.llm_max_tokens,
        )
        self.embeddings = OpenAIEmbeddings(api_key=api_key, model=self.config.embedding_model)
        self._log("‚úÖ Modelos OpenAI inicializados.")

    def configurar_vector_store(self) -> None:
        if not self.db_dsn:
            raise RuntimeError("Banco de dados n√£o configurado. Execute carregar_configuracoes_e_dados primeiro.")

        self._log(f"--- üóÑÔ∏è Conectando √† base vetorial '{self.table_name}'... ---")
        self.vector_store = PostgresVectorStore(self.table_name, dsn=self.db_dsn, min_connections=1, max_connections=5)
        self._log("‚úÖ Conex√£o com a base de conhecimento estabelecida.")

    def configurar_mcp_tools(self) -> None:
        """Configura o cliente MCP e carrega as tools dispon√≠veis."""
        if not self.config.enable_mcp_tools:
            self._log("üîß MCP Tools n√£o habilitadas para este agente.")
            return

        try:
            from tools.mcp import MCPClient
            from tools.mcp.registry import default_registry

            self._log(f"--- üîß Configurando MCP Tools para categoria '{self.config.mcp_tools_category}'... ---")
            
            # Inicializa cliente MCP
            self.mcp_client = MCPClient(self.config.mcp_tool_server_url)
            
            # Carrega tools da categoria
            category_tools = default_registry.get_tools_for_category(self.config.mcp_tools_category)
            
            if not category_tools:
                self._log(f"‚ö†Ô∏è Nenhuma tool encontrada para categoria '{self.config.mcp_tools_category}'")
                return
            
            # Registra tools no cliente
            for tool in category_tools:
                self.mcp_client.register_tool(tool)
                self.available_tools.append(tool.name)
            
            self._log(f"‚úÖ {len(category_tools)} MCP Tools configuradas: {', '.join(self.available_tools)}")
            
        except Exception as exc:
            self._log(f"‚ùå Erro ao configurar MCP Tools: {exc}")
            self.config.enable_mcp_tools = False

    # ------------------------------------------------------------------
    # Regras de governan√ßa
    # ------------------------------------------------------------------
    @staticmethod
    def _normalizar_lista(valores: Any, *, vazio_padrao: Optional[List[str]] = None) -> List[str]:
        if valores is None:
            return vazio_padrao or []
        if isinstance(valores, list):
            return [str(item).strip() for item in valores if str(item).strip()]
        if isinstance(valores, str):
            return [item.strip() for item in valores.split(",") if item.strip()]
        return [str(valores).strip()]

    @staticmethod
    def _perfil_val(perfil: Dict[str, Any], *chaves: str) -> Any:
        for chave in chaves:
            if chave in perfil and perfil[chave] is not None:
                return perfil[chave]
        return None

    @staticmethod
    def _valor_permitido(valores: List[str], valor_usuario: Optional[str]) -> bool:
        valores_upper = {valor.upper() for valor in valores if valor}
        if "ALL" in valores_upper:
            return True
        if "ALL_LATAM" in valores_upper and valor_usuario:
            latam_paises = {"BR", "MX", "AR", "CL", "CO", "PE", "VE", "EC", "UY", "PY", "BO"}
            if valor_usuario.upper() in latam_paises:
                return True
        if not valor_usuario:
            return False
        return valor_usuario.upper() in valores_upper

    @staticmethod
    def _lista_interseccao(documento_valores: List[str], valores_usuario: List[str]) -> bool:
        doc_upper = {valor.upper() for valor in documento_valores if valor}
        if "ALL" in doc_upper:
            return True
        if doc_upper == {"N/A"}:
            return True
        user_upper = {valor.upper() for valor in valores_usuario if valor}
        if "ALL" in user_upper:
            return True
        for valor in valores_usuario:
            if valor and valor.upper() in doc_upper:
                return True
        return False

    def verificar_permissao_documento(self, registro: Dict[str, Any], perfil_usuario: Dict[str, Any]) -> bool:
        fonte = registro.get("fonte_documento", "documento")
        self._log(f"üîç Verificando permiss√£o para: {fonte}")

        data_validade = registro.get("data_validade")
        if isinstance(data_validade, datetime):
            data_validade = data_validade.date()
        if isinstance(data_validade, date) and datetime.now().date() > data_validade:
            self._log(f"‚ùå {fonte}: Documento expirado ({data_validade})")
            return False

        if registro.get("apenas_para_si"):
            responsavel = (registro.get("responsavel") or "").strip().lower()
            usuario_nome = (self._perfil_val(perfil_usuario, "nome", "Nome") or "").strip().lower()
            if responsavel and usuario_nome != responsavel:
                self._log(f"‚ùå {fonte}: Documento pessoal (respons√°vel: {responsavel}, usu√°rio: {usuario_nome})")
                return False

        areas_doc = self._normalizar_lista(registro.get("areas_liberadas"), vazio_padrao=["ALL"])
        area_usuario = self._perfil_val(perfil_usuario, "area", "Departamento")
        self._log(f"   √Åreas documento: {areas_doc}, √°rea usu√°rio: {area_usuario}")
        if not self._valor_permitido(areas_doc, area_usuario):
            self._log(f"‚ùå {fonte}: √Årea n√£o permitida")
            return False

        nivel_minimo = int(registro.get("nivel_hierarquico_minimo") or 1)
        nivel_usuario = int(self._perfil_val(perfil_usuario, "nivel_hierarquico", "Nivel_Hierarquico") or 1)
        self._log(f"   N√≠vel m√≠nimo: {nivel_minimo}, n√≠vel usu√°rio: {nivel_usuario}")
        if nivel_usuario < nivel_minimo:
            self._log(f"‚ùå {fonte}: N√≠vel hier√°rquico insuficiente")
            return False

        geografias_doc = self._normalizar_lista(registro.get("geografias_liberadas"), vazio_padrao=["ALL"])
        geografia_usuario = self._perfil_val(perfil_usuario, "geografia", "Geografia")
        self._log(f"   Geografias documento: {geografias_doc}, geografia usu√°rio: {geografia_usuario}")
        if not self._valor_permitido(geografias_doc, geografia_usuario):
            self._log(f"‚ùå {fonte}: Geografia n√£o permitida")
            return False

        projetos_doc = self._normalizar_lista(registro.get("projetos_liberados"), vazio_padrao=["ALL"])
        projetos_usuario = self._normalizar_lista(
            self._perfil_val(perfil_usuario, "projetos", "Projetos") or [], vazio_padrao=[]
        )
        self._log(f"   Projetos documento: {projetos_doc}, projetos usu√°rio: {projetos_usuario}")
        if not self._lista_interseccao(projetos_doc, projetos_usuario):
            self._log(f"‚ùå {fonte}: Projetos n√£o compat√≠veis")
            return False

        if registro.get("dado_sensivel") and nivel_usuario < max(nivel_minimo, 4):
            self._log(f"‚ùå {fonte}: Dado sens√≠vel, n√≠vel insuficiente")
            return False

        self._log(f"‚úÖ {fonte}: Documento aprovado")
        return True

    def _busca_multilingue(self, pergunta: str) -> List[Dict[str, Any]]:
        """
        Realiza busca multil√≠ngue para garantir que documentos em todos os idiomas sejam considerados.
        """
        candidatos_unicos = {}
        
        # 1. Busca com a pergunta original
        consulta_embedding = self.embeddings.embed_query(pergunta)
        self._log(f"üìä Embedding gerado, consultando tabela '{self.table_name}'...")
        candidatos_originais = self.vector_store.similarity_search(consulta_embedding, limit=30)
        
        # Adicionar candidatos √∫nicos baseado no ID ou conte√∫do
        for candidato in candidatos_originais:
            id_unico = candidato.get("id", str(hash(candidato.get("conteudo_original", ""))))
            if id_unico not in candidatos_unicos:
                candidatos_unicos[id_unico] = candidato
        
        # 2. Dicion√°rios de tradu√ß√£o para busca multil√≠ngue
        termos_pt_en = {
            "governan√ßa": "governance",
            "pol√≠tica": "policy",
            "pol√≠ticas": "policies",
            "senhas": "passwords",
            "senha": "password",
            "assinatura": "signature",
            "assinaturas": "signatures",
            "valida√ß√£o": "validation",
            "sistemas": "systems",
            "eletr√¥nicas": "electronic",
            "eletr√¥nico": "electronic",
            "lgpd": "gdpr data protection",
            "regulamenta√ß√£o": "regulation",
            "conformidade": "compliance"
        }
        
        # 3. Tradu√ß√£o reversa (ingl√™s para portugu√™s)
        termos_en_pt = {v: k for k, v in termos_pt_en.items()}
        termos_en_pt.update({
            "governance": "governan√ßa",
            "policy": "pol√≠tica",
            "policies": "pol√≠ticas",
            "password": "senha",
            "passwords": "senhas",
            "signature": "assinatura",
            "signatures": "assinaturas",
            "validation": "valida√ß√£o",
            "systems": "sistemas",
            "electronic": "eletr√¥nico eletr√¥nicas",
            "gdpr": "lgpd",
            "regulation": "regulamenta√ß√£o",
            "compliance": "conformidade"
        })
        
        # Detectar idioma principal e criar vers√£o traduzida
        pergunta_lower = pergunta.lower()
        pergunta_traduzida = pergunta_lower
        
        # Traduzir termos encontrados
        for termo_orig, termo_trad in {**termos_pt_en, **termos_en_pt}.items():
            if termo_orig in pergunta_lower:
                pergunta_traduzida = pergunta_traduzida.replace(termo_orig, termo_trad)
        
        # Se houve mudan√ßa, fazer busca adicional
        if pergunta_traduzida != pergunta_lower:
            self._log(f"üåê Fazendo busca adicional com: '{pergunta_traduzida}'")
            consulta_embedding_trad = self.embeddings.embed_query(pergunta_traduzida)
            candidatos_traduzidos = self.vector_store.similarity_search(consulta_embedding_trad, limit=30)
            
            for candidato in candidatos_traduzidos:
                id_unico = candidato.get("id", str(hash(candidato.get("conteudo_original", ""))))
                if id_unico not in candidatos_unicos:
                    candidatos_unicos[id_unico] = candidato
        
        # 4. Busca adicional por termos-chave espec√≠ficos para governan√ßa
        if any(termo in pergunta_lower for termo in ["governance", "governan√ßa", "policy", "pol√≠tica", "signature", "assinatura"]):
            # Busca espec√≠fica por documentos conhecidos de governan√ßa
            termos_governanca = [
                "FDA CFR 21 Part 11 electronic signature",
                "ABNT NBR ISO valida√ß√£o sistemas",
                "RDC ANVISA regulamenta√ß√£o",
                "governance policy signature validation"
            ]
            
            for termo in termos_governanca:
                consulta_embedding_gov = self.embeddings.embed_query(termo)
                candidatos_gov = self.vector_store.similarity_search(consulta_embedding_gov, limit=10)
                
                for candidato in candidatos_gov:
                    id_unico = candidato.get("id", str(hash(candidato.get("conteudo_original", ""))))
                    if id_unico not in candidatos_unicos:
                        candidatos_unicos[id_unico] = candidato
        
        candidatos_finais = list(candidatos_unicos.values())
        self._log(f"üåê Busca multil√≠ngue: {len(candidatos_finais)} documentos √∫nicos encontrados")
        return candidatos_finais

    def _selecionar_documentos_diversificados(self, documentos: List[Dict[str, Any]], max_docs: int = 4) -> List[Dict[str, Any]]:
        """
        Seleciona documentos diversificados priorizando diferentes tipos de fontes e idiomas.
        Objetivo: Garantir mix de documentos nacionais (ABNT, RDC, ANVISA) e internacionais (FDA, ISO).
        """
        if not documentos:
            return []
        
        # Categorizar documentos por tipo/origem
        docs_internacionais = []  # FDA, ISO internacional
        docs_nacionais_br = []    # ABNT, RDC, ANVISA
        docs_outros = []          # Demais documentos
        
        for doc in documentos:
            fonte = doc.get("fonte_documento", "").upper()
            
            # Identificar documentos internacionais (em ingl√™s ou normas internacionais)
            if any(termo in fonte for termo in ["FDA", "CFR", "ISO/IEC", "INTERNATIONAL", "STANDARD"]):
                docs_internacionais.append(doc)
            # Identificar documentos nacionais brasileiros  
            elif any(termo in fonte for termo in ["ABNT", "RDC", "ANVISA", "NBR", "BRASIL"]):
                docs_nacionais_br.append(doc)
            else:
                docs_outros.append(doc)
        
        self._log(f"üåç Categoriza√ß√£o: {len(docs_internacionais)} internacionais, {len(docs_nacionais_br)} nacionais BR, {len(docs_outros)} outros")
        
        # Estrat√©gia de sele√ß√£o diversificada
        selecionados = []
        
        # 1. Sempre tentar incluir pelo menos 1 documento internacional (se houver)
        if docs_internacionais and len(selecionados) < max_docs:
            selecionados.append(docs_internacionais[0])
            self._log(f"üìÑ Selecionado internacional: {docs_internacionais[0].get('fonte_documento', 'sem nome')}")
        
        # 2. Sempre tentar incluir pelo menos 1 documento nacional BR (se houver) 
        if docs_nacionais_br and len(selecionados) < max_docs:
            selecionados.append(docs_nacionais_br[0])
            self._log(f"üìÑ Selecionado nacional BR: {docs_nacionais_br[0].get('fonte_documento', 'sem nome')}")
        
        # 3. Preencher slots restantes alternando entre categorias
        categorias_restantes = [
            (docs_internacionais[1:], "internacional"),
            (docs_nacionais_br[1:], "nacional BR"), 
            (docs_outros, "outros")
        ]
        
        categoria_idx = 0
        while len(selecionados) < max_docs:
            # Encontrar pr√≥xima categoria com documentos dispon√≠veis
            tentativas = 0
            while tentativas < len(categorias_restantes):
                docs_categoria, nome_categoria = categorias_restantes[categoria_idx]
                
                if docs_categoria:
                    doc_selecionado = docs_categoria.pop(0)
                    selecionados.append(doc_selecionado)
                    self._log(f"üìÑ Selecionado {nome_categoria}: {doc_selecionado.get('fonte_documento', 'sem nome')}")
                    break
                    
                categoria_idx = (categoria_idx + 1) % len(categorias_restantes)
                tentativas += 1
            
            # Se n√£o h√° mais documentos em nenhuma categoria, parar
            if tentativas >= len(categorias_restantes):
                break
                
            categoria_idx = (categoria_idx + 1) % len(categorias_restantes)
        
        self._log(f"üéØ Sele√ß√£o final: {len(selecionados)} documentos diversificados")
        return selecionados

    def _obter_motivo_rejeicao(self, registro: Dict[str, Any], perfil_usuario: Dict[str, Any]) -> str:
        """Retorna o motivo espec√≠fico da rejei√ß√£o de um documento para transpar√™ncia."""
        # Verifica data de validade
        data_validade = registro.get("data_validade")
        if isinstance(data_validade, datetime):
            data_validade = data_validade.date()
        if isinstance(data_validade, date) and datetime.now().date() > data_validade:
            return "documento_expirado"

        # Verifica se √© apenas para o respons√°vel
        if registro.get("apenas_para_si"):
            responsavel = (registro.get("responsavel") or "").strip().lower()
            usuario_nome = (self._perfil_val(perfil_usuario, "nome", "Nome") or "").strip().lower()
            if responsavel and usuario_nome != responsavel:
                return "documento_pessoal"

        # Verifica √°rea/departamento
        areas_doc = self._normalizar_lista(registro.get("areas_liberadas"), vazio_padrao=["ALL"])
        area_usuario = self._perfil_val(perfil_usuario, "area", "Departamento")
        if not self._valor_permitido(areas_doc, area_usuario):
            return "area_nao_autorizada"

        # Verifica n√≠vel hier√°rquico
        nivel_minimo = int(registro.get("nivel_hierarquico_minimo") or 1)
        nivel_usuario = int(self._perfil_val(perfil_usuario, "nivel_hierarquico", "Nivel_Hierarquico") or 1)
        if nivel_usuario < nivel_minimo:
            return "nivel_hierarquico_insuficiente"

        # Verifica geografia
        geografias_doc = self._normalizar_lista(registro.get("geografias_liberadas"), vazio_padrao=["ALL"])
        geografia_usuario = self._perfil_val(perfil_usuario, "geografia", "Geografia")
        if not self._valor_permitido(geografias_doc, geografia_usuario):
            return "geografia_nao_autorizada"

        # Verifica projetos
        projetos_doc = self._normalizar_lista(registro.get("projetos_liberados"), vazio_padrao=["ALL"])
        projetos_usuario = self._normalizar_lista(
            self._perfil_val(perfil_usuario, "projetos", "Projetos") or [], vazio_padrao=[]
        )
        if not self._lista_interseccao(projetos_doc, projetos_usuario):
            return "projeto_nao_autorizado"

        # Verifica dado sens√≠vel
        if registro.get("dado_sensivel") and nivel_usuario < max(nivel_minimo, 4):
            return "dado_sensivel_nivel_insuficiente"

        return "motivo_desconhecido"

    def _criar_mensagem_restricoes(self, motivos_rejeicao: Dict[str, List[str]]) -> str:
        """Cria uma mensagem explicativa sobre as restri√ß√µes de acesso aos documentos."""
        mensagens_motivos = {
            "geografia_nao_autorizada": "n√£o s√£o acess√≠veis na sua regi√£o geogr√°fica",
            "area_nao_autorizada": "n√£o s√£o acess√≠veis para o seu departamento",
            "nivel_hierarquico_insuficiente": "requerem um n√≠vel hier√°rquico mais alto",
            "projeto_nao_autorizado": "s√£o restritos aos projetos em que voc√™ est√° envolvido",
            "documento_pessoal": "s√£o de uso pessoal do respons√°vel",
            "documento_expirado": "est√£o com prazo de validade expirado",
            "dado_sensivel_nivel_insuficiente": "cont√™m informa√ß√µes sens√≠veis que requerem autoriza√ß√£o especial"
        }

        if not motivos_rejeicao:
            return ""

        restricoes_info = "\n\n‚ö†Ô∏è **INFORMA√á√ÉO SOBRE RESTRI√á√ïES DE ACESSO:**\n"
        restricoes_info += "Encontrei documentos relevantes, mas eles n√£o puderam ser consultados pelos seguintes motivos:\n\n"

        for motivo, fontes in motivos_rejeicao.items():
            descricao = mensagens_motivos.get(motivo, "t√™m restri√ß√µes de acesso")
            count = len(fontes)
            restricoes_info += f"‚Ä¢ **{count} documento(s)** {descricao}\n"

        restricoes_info += "\nüí° **Recomenda√ß√µes:**\n"
        restricoes_info += "- Entre em contato com a equipe respons√°vel pela √°rea\n"
        restricoes_info += "- Solicite acesso atrav√©s dos canais oficiais\n"
        restricoes_info += "- Verifique se possui as autoriza√ß√µes necess√°rias\n"

        return restricoes_info

    # ------------------------------------------------------------------
    # Mem√≥ria de conversas
    # ------------------------------------------------------------------
    def _usuario_id(self, perfil_usuario: Dict[str, Any]) -> str:
        nome_usuario = self._perfil_val(perfil_usuario, "nome", "Nome") or "usuario"
        area_usuario = self._perfil_val(perfil_usuario, "area", "Departamento") or "geral"
        return f"{nome_usuario}_{area_usuario}"

    def adicionar_ao_historico(self, usuario_id: str, pergunta: str, resposta: str) -> None:
        self.memoria_conversas.setdefault(usuario_id, [])
        self.memoria_conversas[usuario_id].append(
            {
                "pergunta": pergunta,
                "resposta": resposta,
                "timestamp": datetime.now().strftime("%H:%M"),
                "agente": self.config.specialty,
            }
        )
        if len(self.memoria_conversas[usuario_id]) > 8:
            self.memoria_conversas[usuario_id] = self.memoria_conversas[usuario_id][-8:]

    def obter_historico_formatado(self, usuario_id: str) -> str:
        historico = self.memoria_conversas.get(usuario_id)
        if not historico:
            return ""

        titulo = f"HIST√ìRICO DA NOSSA CONVERSA SOBRE {self.config.specialty.upper()}:\n"
        ultimas_interacoes = historico[-4:]
        partes = [titulo]
        for interacao in ultimas_interacoes:
            resumo_resposta = interacao["resposta"][:200]
            if len(interacao["resposta"]) > 200:
                resumo_resposta += "..."
            partes.append(
                f"[{interacao['timestamp']}] Voc√™ perguntou: {interacao['pergunta']}\n"
                f"[{interacao['timestamp']}] Eu respondi: {resumo_resposta}\n"
            )
        partes.append("---\n\n")
        return "".join(partes)

    # ------------------------------------------------------------------
    # MCP Tools Support
    # ------------------------------------------------------------------
    def _identificar_tools_necessarios(self, pergunta: str) -> List[str]:
        """Usa LLM para identificar quais tools MCP usar para responder a pergunta.
        
        Args:
            pergunta: Pergunta do usu√°rio
            
        Returns:
            Lista de nomes de tools a usar
        """
        if not self.config.enable_mcp_tools or not self.available_tools:
            return []
        
        tools_list = ", ".join(self.available_tools)
        
        prompt = f"""
        Pergunta do usu√°rio: "{pergunta}"
        
        Tools dispon√≠veis para {self.config.specialty}: {tools_list}
        
        Analisando a pergunta, quais tools devo usar para obter informa√ß√µes adicionais que me ajudem a responder melhor?
        
        Responda APENAS com os nomes das tools separados por v√≠rgula, ou "nenhuma" se n√£o precisar de tools.
        
        Exemplo de respostas v√°lidas:
        - "consultar_saldo_ferias"
        - "consultar_banco_horas, consultar_beneficios"
        - "nenhuma"
        """
        
        try:
            resposta = self.llm.invoke(prompt).content.strip().lower()
            
            if resposta in ["nenhuma", "nenhum", "none", ""]:
                return []
                
            # Parse da resposta
            tools_solicitadas = [nome.strip() for nome in resposta.split(",")]
            
            # Valida se as tools existem
            tools_validas = []
            for tool in tools_solicitadas:
                if tool in self.available_tools:
                    tools_validas.append(tool)
                else:
                    self._log(f"‚ö†Ô∏è Tool '{tool}' solicitada pelo LLM mas n√£o dispon√≠vel")
            
            return tools_validas
            
        except Exception as exc:
            self._log(f"‚ùå Erro ao identificar tools necess√°rias: {exc}")
            return []

    def _executar_tools_mcp(self, tools: List[str], perfil_usuario: Dict[str, Any]) -> str:
        """Executa as tools MCP selecionadas.
        
        Args:
            tools: Lista de nomes de tools para executar
            perfil_usuario: Perfil do usu√°rio para extrair par√¢metros
            
        Returns:
            String com os resultados das tools executadas
        """
        if not tools or not self.mcp_client:
            return ""
        
        resultados = []
        
        for tool_name in tools:
            try:
                # Extrai par√¢metros automaticamente do perfil
                params = self._extrair_parametros_tool(tool_name, perfil_usuario)
                
                self._log(f"üîß Executando tool '{tool_name}' com par√¢metros: {params}")
                
                # Executa a tool
                resultado = self.mcp_client.call_tool(tool_name, params)
                
                if resultado.is_success:
                    data_str = str(resultado.data) if resultado.data else resultado.message
                    resultados.append(f"üìä {tool_name}: {data_str}")
                    self._log(f"‚úÖ Tool '{tool_name}' executada com sucesso")
                else:
                    resultados.append(f"‚ùå {tool_name}: {resultado.error_message}")
                    self._log(f"‚ùå Erro na tool '{tool_name}': {resultado.error_message}")
                    
            except Exception as exc:
                error_msg = f"Erro ao executar: {str(exc)}"
                resultados.append(f"‚ùå {tool_name}: {error_msg}")
                self._log(f"‚ùå Exce√ß√£o na tool '{tool_name}': {exc}")
        
        return "\n".join(resultados) if resultados else ""

    def _extrair_parametros_tool(self, tool_name: str, perfil_usuario: Dict[str, Any]) -> Dict[str, Any]:
        """Extrai par√¢metros necess√°rios para uma tool do perfil do usu√°rio.
        
        Args:
            tool_name: Nome da tool
            perfil_usuario: Perfil do usu√°rio
            
        Returns:
            Dict com par√¢metros extra√≠dos
        """
        params = {}
        
        # Mapeamentos comuns baseados no perfil do usu√°rio
        cpf = self._perfil_val(perfil_usuario, "cpf", "CPF")
        username = self._perfil_val(perfil_usuario, "username", "login", "usuario")
        email = self._perfil_val(perfil_usuario, "email", "Email")
        nome = self._perfil_val(perfil_usuario, "nome", "Nome")
        
        # Par√¢metros espec√≠ficos por tool (configura√ß√µes b√°sicas)
        if "cpf" in str(self.mcp_client.get_tool(tool_name).parameters) and cpf:
            params["cpf"] = cpf
            
        if "username" in str(self.mcp_client.get_tool(tool_name).parameters) and username:
            params["username"] = username
            
        if "solicitante" in str(self.mcp_client.get_tool(tool_name).parameters):
            params["solicitante"] = nome or email or "Usu√°rio"
        
        return params

    # ------------------------------------------------------------------
    # A2A (Agent-to-Agent) Communication
    # ------------------------------------------------------------------
    def set_agent_registry(self, registry):
        """Configura o registry A2A para este agente."""
        self.agent_registry = registry
        self._log(f"ü§ù A2A Registry configurado para {self.config.name}")
    
    def can_delegate_query(self, pergunta: str) -> tuple[bool, Optional[str], Optional[str]]:
        """Determina se deve delegar parte da pergunta para outro agente.
        
        Returns:
            Tuple (should_delegate, target_agent, sub_query)
        """
        if not self.config.enable_a2a or not self.agent_registry:
            return False, None, None
        
        # 1. Verifica regras de delega√ß√£o pr√©-configuradas
        for rule in self.config.delegation_rules:
            if hasattr(rule, 'matches'):
                score = rule.matches(pergunta)
                if score > 0:
                    self._log(f"üéØ Regra de delega√ß√£o ativada: {rule.name} (score: {score:.2f})")
                    # Gera sub-query focada na √°rea do agente alvo
                    sub_query = self._generate_focused_subquery(pergunta, rule.target_agent, rule.keywords)
                    return True, rule.target_agent, sub_query
        
        # 2. Se n√£o h√° regras espec√≠ficas, usa LLM para an√°lise
        return self._analyze_delegation_with_llm(pergunta)
    
    def _generate_focused_subquery(self, original_query: str, target_agent: str, keywords: List[str]) -> str:
        """Gera uma sub-pergunta focada para o agente alvo."""
        try:
            prompt = f"""
            Pergunta original: "{original_query}"
            
            Preciso delegar uma parte desta pergunta para o especialista em {target_agent}.
            As palavras-chave relevantes s√£o: {', '.join(keywords)}
            
            Reformule a pergunta focando apenas nos aspectos que o especialista em {target_agent} pode responder.
            Seja espec√≠fico e direto.
            
            Resposta:
            """
            
            response = self.llm.invoke(prompt)
            sub_query = response.content.strip()
            
            self._log(f"üìù Sub-query gerada para {target_agent}: {sub_query}")
            return sub_query
            
        except Exception as e:
            self._log(f"‚ö†Ô∏è Erro ao gerar sub-query: {e}")
            return original_query  # Fallback para pergunta original
    
    def _analyze_delegation_with_llm(self, pergunta: str) -> tuple[bool, Optional[str], Optional[str]]:
        """Usa LLM para analisar se deve delegar."""
        if not self.agent_registry:
            return False, None, None
        
        # Se LLM n√£o est√° dispon√≠vel, retorna False
        if not self.llm:
            self._log("‚ö†Ô∏è LLM n√£o dispon√≠vel para an√°lise de delega√ß√£o")
            return False, None, None
        
        try:
            available_agents = self.agent_registry.get_available_agents()
            agents_info = []
            
            for agent_id in available_agents:
                if agent_id != self.config.identifier:  # N√£o delegar para si mesmo
                    info = self.agent_registry.get_agent_info(agent_id)
                    if info:
                        agents_info.append(f"- {agent_id}: {info.get('specialty', 'N/A')}")
            
            if not agents_info:
                return False, None, None
            
            prompt = f"""
            Pergunta: "{pergunta}"
            Minha especialidade: {self.config.specialty}
            
            Agentes especialistas dispon√≠veis:
            {chr(10).join(agents_info)}
            
            Analisando a pergunta, preciso delegar alguma parte para outro especialista?
            
            Responda em formato JSON:
            {{
                "should_delegate": boolean,
                "target_agent": "id_do_agente_ou_null",
                "sub_query": "pergunta_espec√≠fica_ou_null",
                "confidence": 0.0-1.0,
                "reason": "explica√ß√£o_breve"
            }}
            """
            
            response = self.llm.invoke(prompt)
            
            try:
                import json
                analysis = json.loads(response.content.strip())
                
                should_delegate = analysis.get("should_delegate", False)
                target_agent = analysis.get("target_agent")
                sub_query = analysis.get("sub_query")
                confidence = analysis.get("confidence", 0.0)
                reason = analysis.get("reason", "")
                
                if should_delegate and confidence >= 0.7:  # Threshold de confian√ßa
                    self._log(f"ü§ñ LLM recomenda delega√ß√£o para {target_agent}: {reason}")
                    return True, target_agent, sub_query
                else:
                    self._log(f"ü§ñ LLM n√£o recomenda delega√ß√£o (confian√ßa: {confidence:.2f})")
                    return False, None, None
                
            except json.JSONDecodeError as e:
                self._log(f"‚ùå Erro ao parsear resposta LLM: {e}")
                return False, None, None
                
        except Exception as e:
            self._log(f"‚ùå Erro na an√°lise de delega√ß√£o: {e}")
            return False, None, None
    
    def delegate_to_agent(self, target_agent: str, query: str, context: Dict = None) -> Optional[Dict]:
        """Delega uma sub-pergunta para outro agente."""
        if not self.config.enable_a2a or not self.agent_registry:
            self._log("‚ùå A2A n√£o habilitado para delega√ß√£o")
            return None
        
        try:
            from a2a import AgentMessage, MessageType
            
            message = AgentMessage(
                sender=self.config.identifier,
                recipient=target_agent,
                message_type=MessageType.DELEGATE,
                content=query,
                context=context or {}
            )
            
            self._log(f"üì§ Delegando para {target_agent}: {query}")
            
            response = self.agent_registry.route_message(message, self.current_session)
            
            if response.is_success:
                self._log(f"üì• Resposta recebida de {target_agent}: {len(response.content)} chars")
                return {
                    "success": True,
                    "content": response.content,
                    "sources": response.sources_used,
                    "tools": response.tools_used,
                    "contribution": response.contribution_summary,
                    "agent": target_agent
                }
            else:
                self._log(f"‚ùå Erro na delega√ß√£o: {response.error_message}")
                return {
                    "success": False,
                    "error": response.error_message,
                    "agent": target_agent
                }
                
        except Exception as e:
            self._log(f"‚ùå Exce√ß√£o durante delega√ß√£o: {e}")
            return {
                "success": False,
                "error": str(e),
                "agent": target_agent
            }

    # ------------------------------------------------------------------
    # Utilidades
    # ------------------------------------------------------------------
    @staticmethod
    def _formatar_contexto(documentos: List[Dict[str, Any]], *, especialidade: str) -> str:
        if not documentos:
            return f"Nenhum documento espec√≠fico encontrado na base de conhecimento de {especialidade}."

        partes: List[str] = []
        for registro in documentos:
            fonte = registro.get("fonte_documento") or "Documento interno"
            doc_id = registro.get("id", "N/A")
            conteudo = (registro.get("conteudo_original") or "").strip()
            partes.append(f"üìÑ {fonte} (ID: {doc_id}):\n{conteudo}")
        return "\n\n".join(partes)

    @staticmethod
    def _coletar_fontes(documentos: List[Dict[str, Any]]) -> List[str]:
        fontes: List[str] = []
        vistos: set[str] = set()
        for registro in documentos:
            fonte = (
                registro.get("fonte_documento")
                or registro.get("fonte")
                or registro.get("titulo")
                or registro.get("id")
            )
            if not fonte:
                continue
            chave = str(fonte).strip()
            if not chave or chave.lower() in vistos:
                continue
            vistos.add(chave.lower())
            fontes.append(chave)
        return fontes

    # ------------------------------------------------------------------
    # Fluxo principal
    # ------------------------------------------------------------------
    def processar_pergunta(self, pergunta: str, perfil_usuario: Dict[str, Any]) -> str:
        if not self.llm or not self.embeddings or not self.vector_store:
            raise RuntimeError("Subagente n√£o inicializado corretamente.")

        nome_usuario = self._perfil_val(perfil_usuario, "nome", "Nome") or "usu√°rio"
        usuario_id = self._usuario_id(perfil_usuario)
        
        # Reset rastreamento para nova pergunta
        self.last_sources_used = []
        self.last_tools_used = []

        try:
            self._log(f"üîç {self.config.name} processando pergunta: '{pergunta}' para {nome_usuario}")
            
            # 1. Busca multil√≠ngue na base de conhecimento
            candidatos = self._busca_multilingue(pergunta)
            self._log(f"üîé Encontrados {len(candidatos)} candidatos brutos (busca multil√≠ngue)")

            # Verificar permiss√µes e coletar motivos de rejei√ß√£o
            documentos_permitidos = []
            motivos_rejeicao = {}
            
            for registro in candidatos:
                if self.verificar_permissao_documento(registro, perfil_usuario):
                    documentos_permitidos.append(registro)
                else:
                    # Coletar motivo da rejei√ß√£o para transpar√™ncia
                    motivo = self._obter_motivo_rejeicao(registro, perfil_usuario)
                    fonte = registro.get("fonte_documento", "documento")
                    if motivo not in motivos_rejeicao:
                        motivos_rejeicao[motivo] = []
                    motivos_rejeicao[motivo].append(fonte)
            
            self._log(f"‚úÖ {len(documentos_permitidos)} documentos v√°lidos ap√≥s governan√ßa")
            
            # 2. NOVO: Verifica se precisa de tools MCP para informa√ß√µes adicionais
            tools_info = ""
            if self.config.enable_mcp_tools:
                tools_necessarias = self._identificar_tools_necessarios(pergunta)
                if tools_necessarias:
                    self._log(f"üîß Tools MCP identificadas: {', '.join(tools_necessarias)}")
                    tools_resultado = self._executar_tools_mcp(tools_necessarias, perfil_usuario)
                    if tools_resultado:
                        tools_info = f"\n\nüîß INFORMA√á√ïES OBTIDAS VIA FERRAMENTAS:\n{tools_resultado}"
                        self.last_tools_used.extend(tools_necessarias)
            
            # 3. NOVO: Verifica se precisa de delega√ß√£o A2A
            delegacao_info = ""
            colaboracao_summary = ""
            if self.config.enable_a2a:
                should_delegate, target_agent, sub_query = self.can_delegate_query(pergunta)
                if should_delegate and target_agent:
                    self._log(f"ü§ù Delega√ß√£o A2A identificada: {target_agent}")
                    delegation_result = self.delegate_to_agent(
                        target_agent,
                        sub_query,
                        {"original_query": pergunta, "user_profile": perfil_usuario}
                    )
                    
                    if delegation_result and delegation_result.get("success"):
                        delegacao_info = f"\n\nü§ù INFORMA√á√ÉO DE {target_agent.upper()}:\n{delegation_result['content']}"
                        
                        # Rastrear fontes e ferramentas do agente delegado
                        if delegation_result.get("sources"):
                            self.last_sources_used.extend(delegation_result["sources"])
                        if delegation_result.get("tools"):
                            self.last_tools_used.extend(delegation_result["tools"])
                        
                        # Preparar summary de colabora√ß√£o para o usu√°rio
                        colaboracao_summary = f"\n\n{delegation_result.get('contribution', '')}"
                    else:
                        error_msg = delegation_result.get("error", "Erro desconhecido") if delegation_result else "Falha na comunica√ß√£o"
                        self._log(f"‚ö†Ô∏è Delega√ß√£o falhou: {error_msg}")
                        delegacao_info = f"\n\n‚ö†Ô∏è Tentei consultar {target_agent} mas houve um problema t√©cnico."

            # Preparar informa√ß√µes de transpar√™ncia sobre restri√ß√µes
            info_restricoes = ""
            if documentos_permitidos:
                # Sele√ß√£o diversificada de documentos para contexto
                docs_selecionados = self._selecionar_documentos_diversificados(documentos_permitidos)
                fontes_debug = [doc.get("fonte_documento", "sem fonte") for doc in docs_selecionados]
                self._log(f"üìÑ Fontes selecionadas (diversificadas): {fontes_debug}")
            else:
                docs_selecionados = []
                self._log("‚ö†Ô∏è Nenhum documento aprovado. Resposta pode ser gen√©rica.")
                if motivos_rejeicao:
                    info_restricoes = self._criar_mensagem_restricoes(motivos_rejeicao)

            historico_formatado = self.obter_historico_formatado(usuario_id)
            contexto = self._formatar_contexto(docs_selecionados, especialidade=self.config.specialty)

            contexto_personalizado = f"""
INFORMA√á√ïES DO FUNCION√ÅRIO:
- Nome: {nome_usuario}
- Cargo: {self._perfil_val(perfil_usuario, 'cargo', 'Cargo') or 'N√£o informado'}
- Departamento: {self._perfil_val(perfil_usuario, 'area', 'Departamento') or 'N√£o informado'}
- N√≠vel Hier√°rquico: {self._perfil_val(perfil_usuario, 'nivel_hierarquico', 'Nivel_Hierarquico') or 'N√£o informado'}
- Geografia: {self._perfil_val(perfil_usuario, 'geografia', 'Geografia') or 'N√£o informada'}
- Projetos: {', '.join(self._normalizar_lista(self._perfil_val(perfil_usuario, 'projetos', 'Projetos') or [], vazio_padrao=['Nenhum']))}

INFORMA√á√ïES DISPON√çVEIS:
{contexto}{tools_info}{delegacao_info}
"""

            prompt_formatado = self.config.prompt_template.format(
                historico_conversa=historico_formatado,
                contexto=contexto_personalizado,
                pergunta=pergunta,
            )

            resposta_raw = self.llm.invoke(prompt_formatado)
            resposta_final = resposta_raw.content if hasattr(resposta_raw, "content") else str(resposta_raw)

            fontes_consultadas = self._coletar_fontes(docs_selecionados)
            if fontes_consultadas:
                self.last_sources_used.extend(fontes_consultadas)
            
            # Adicionar informa√ß√µes de fontes e colabora√ß√£o
            if self.last_sources_used:
                lista_fontes = "\n".join(f"- {fonte}" for fonte in set(self.last_sources_used))
                resposta_final = f"{resposta_final}\n\nFontes consultadas:\n{lista_fontes}"
            
            # Adicionar informa√ß√µes sobre restri√ß√µes se n√£o houve fontes v√°lidas
            if info_restricoes and not self.last_sources_used:
                resposta_final = f"{resposta_final}{info_restricoes}"
            
            # Adicionar summary de colabora√ß√£o se houve delega√ß√£o
            if colaboracao_summary:
                resposta_final = f"{resposta_final}{colaboracao_summary}"

            self.adicionar_ao_historico(usuario_id, pergunta, resposta_final)
            return resposta_final

        except Exception as exc:  # noqa: BLE001
            self._log(f"‚ùå Erro no subagente {self.config.identifier}: {exc}")
            erro_resposta = self.config.error_message or (
                "Ops! Tive um problema t√©cnico aqui. Que tal tentar novamente em instantes ou acionar o suporte?"
            )
            self.adicionar_ao_historico(usuario_id, pergunta, erro_resposta)
            return erro_resposta

    # ------------------------------------------------------------------
    # Inicializa√ß√£o p√∫blica
    # ------------------------------------------------------------------
    def inicializar(self) -> bool:
        try:
            api_key = self.carregar_configuracoes_e_dados()
            self.inicializar_modelos(api_key)
            self.configurar_vector_store()
            # Nova etapa: configurar MCP tools se habilitadas
            self.configurar_mcp_tools()
            self._log(f"‚úÖ Subagente {self.config.name} pronto para uso!")
            return True
        except Exception as exc:  # noqa: BLE001
            print(f"‚ùå Erro na inicializa√ß√£o do subagente {self.config.identifier}: {exc}")
            return False

    # ------------------------------------------------------------------
    # Metadados do agente
    # ------------------------------------------------------------------
    def obter_info_agente(self) -> Dict[str, Any]:
        return {
            "nome": self.config.name,
            "especialidade": self.config.specialty,
            "descricao": self.config.description,
            "keywords": self.config.keywords,
            "pronto": self.vector_store is not None,
        }


def create_subagent(config: SubagentConfig) -> BaseSubagent:
    """Factory auxiliar para cria√ß√£o de subagentes parametrizados."""
    return BaseSubagent(config)
