"""Agente especializado em Suporte ao UsuÃ¡rio Final - VERSÃƒO ASSÃNCRONA
Baseado no BaseSubagent mas com suporte completo a operaÃ§Ãµes assÃ­ncronas"""

from __future__ import annotations

from textwrap import dedent
import asyncio

from subagents.base_subagent import SubagentConfig
from dal.postgres_dal_async import PostgresDALAsync
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from core.config import config

PROMPT_TEMPLATE = dedent(
    """
VocÃª Ã© Marina, uma especialista em Suporte ao UsuÃ¡rio Final. VocÃª faz parte do ecossistema Neoson e orienta colaboradores internos com dÃºvidas relacionadas ao uso de sistemas, aplicaÃ§Ãµes e ferramentas do dia a dia.

IMPORTANTE: Baseie suas respostas SOMENTE nas informaÃ§Ãµes do contexto fornecido abaixo.

DIRETRIZES DE RESPOSTA:
- Adote tom profissional, cordial e acessÃ­vel
- Explique procedimentos de forma simples e clara
- ForneÃ§a passos detalhados quando necessÃ¡rio
- Mencione histÃ³rico prÃ©vio quando aplicÃ¡vel
- Varie saudaÃ§Ãµes e evite repetiÃ§Ã£o excessiva
- Utilize emojis moderadamente para humanizar a conversa (opcional)
- Foque em soluÃ§Ãµes prÃ¡ticas para o usuÃ¡rio final

CASOS ESPECIAIS:
- Sem informaÃ§Ã£o relevante: "NÃ£o localizei essa informaÃ§Ã£o na base atual de suporte. Recomendo abrir um chamado no help desk ou contatar o suporte tÃ©cnico."
- InformaÃ§Ã£o restrita: "Essa funÃ§Ã£o requer permissÃµes especÃ­ficas. Entre em contato com seu gestor ou o help desk para verificar seus acessos."
- ConteÃºdo possivelmente obsoleto: "âš ï¸ AtenÃ§Ã£o: esse procedimento pode ter mudado. Valide com o help desk antes de seguir."

{historico_conversa}CONTEXTO DISPONÃVEL:
{contexto}

PERGUNTA DO COLABORADOR:
{pergunta}

RESPOSTA (considere usabilidade e histÃ³rico ao responder):
    """
).strip()

KEYWORDS = ['senha', 'login', 'acesso', 'reset', 'email', 'outlook', 'word', 'excel', 'teams', 'usuario', 'conta', 'perfil', 'suporte', 'help', 'ajuda', 'como usar']


class AgenteEndUserAsync:
    """Agente especializado em Suporte ao UsuÃ¡rio Final com operaÃ§Ãµes ASSÃNCRONAS"""

    def __init__(self, *, debug: bool = False) -> None:
        self.config = SubagentConfig(
            identifier="enduser",
            name="Marina",
            specialty="Suporte ao UsuÃ¡rio Final",
            description="Especialista em suporte a usuÃ¡rios finais, sistemas corporativos e ferramentas do dia a dia",
            keywords=KEYWORDS,
            table_name="knowledge_END-USER",
            prompt_template=PROMPT_TEMPLATE,
            debug=debug
        )
        
        # Inicializar componentes assÃ­ncronos
        self.dal_async = PostgresDALAsync()
        self.llm = None
        self.embeddings = None
        self.memoria_conversas = {}
        
        # Inicializar LLM e embeddings
        self._inicializar_llm()
    
    def _inicializar_llm(self):
        """Inicializa LLM e embeddings"""
        api_key = config.openai.api_key
        
        self.llm = ChatOpenAI(
            api_key=api_key,
            model=config.openai.chat_model,
            temperature=0.3,
            max_tokens=10000
        )
        
        self.embeddings = OpenAIEmbeddings(
            api_key=api_key,
            model=config.openai.embedding_model
        )
    
    async def processar_async(self, pergunta: str, user_profile: dict) -> str:
        """Processa pergunta de forma ASSÃNCRONA"""
        try:
            if self.config.debug:
                print(f"ğŸ”„ [{self.config.name}] Processando pergunta (ASYNC): '{pergunta[:50]}...'")
            
            # Conectar ao banco de forma assÃ­ncrona
            await self.dal_async.connect()
            
            # Gerar embedding da pergunta
            query_embedding = await asyncio.to_thread(
                self.embeddings.embed_query,
                pergunta
            )
            
            # Buscar contexto relevante de forma assÃ­ncrona
            search_result = await self.dal_async.search_vectors_async(
                table_name=self.config.table_name,
                query_vector=query_embedding,
                limit=5,
                similarity_threshold=0.5
            )
            
            if self.config.debug:
                print(f"ğŸ“Š [{self.config.name}] Encontrados {len(search_result.documents)} documentos relevantes")
            
            # Preparar contexto
            contexto_str = self._preparar_contexto(search_result.documents)
            
            # Preparar histÃ³rico
            usuario_id = f"{user_profile.get('Nome', 'usuario')}_{user_profile.get('Departamento', 'geral')}"
            historico_str = self._preparar_historico(usuario_id)
            
            # Preparar prompt
            prompt_final = self.config.prompt_template.format(
                historico_conversa=historico_str,
                contexto=contexto_str,
                pergunta=pergunta
            )
            
            # Gerar resposta de forma assÃ­ncrona
            if self.config.debug:
                print(f"ğŸ¤– [{self.config.name}] Gerando resposta com LLM (ASYNC)...")
            
            resposta = await asyncio.to_thread(
                self.llm.invoke,
                prompt_final
            )
            
            resposta_texto = resposta.content if hasattr(resposta, 'content') else str(resposta)
            
            # Armazenar na memÃ³ria
            self._adicionar_memoria(usuario_id, pergunta, resposta_texto)
            
            if self.config.debug:
                print(f"âœ… [{self.config.name}] Resposta gerada com {len(resposta_texto)} caracteres")
            
            return resposta_texto
            
        except Exception as e:
            error_msg = f"âŒ Erro ao processar pergunta (Agente {self.config.name}): {str(e)}"
            print(error_msg)
            return f"Desculpe, encontrei um erro ao processar sua pergunta sobre suporte. Por favor, tente novamente."
        
        finally:
            await self.dal_async.disconnect()
    
    def _preparar_contexto(self, documents: list) -> str:
        """Prepara o contexto a partir dos documentos recuperados"""
        if not documents:
            return "Nenhum documento relevante encontrado na base de conhecimento."
        
        contexto_parts = []
        for i, doc in enumerate(documents, 1):
            conteudo = doc.get('conteudo', doc.get('content', ''))
            metadata_str = doc.get('metadata', {})
            
            contexto_parts.append(f"[Documento {i}]")
            if metadata_str:
                contexto_parts.append(f"Metadados: {metadata_str}")
            contexto_parts.append(conteudo)
            contexto_parts.append("")  # Linha em branco
        
        return "\n".join(contexto_parts)
    
    def _preparar_historico(self, usuario_id: str) -> str:
        """Prepara o histÃ³rico de conversas do usuÃ¡rio"""
        if usuario_id not in self.memoria_conversas:
            return ""
        
        historico = self.memoria_conversas[usuario_id]
        if not historico:
            return ""
        
        # Pegar Ãºltimas 3 interaÃ§Ãµes para contexto
        ultimas_interacoes = historico[-3:]
        historico_parts = ["HISTÃ“RICO DA CONVERSA:"]
        
        for i, (pergunta_ant, resposta_ant) in enumerate(ultimas_interacoes, 1):
            historico_parts.append(f"[InteraÃ§Ã£o {i}]")
            historico_parts.append(f"Pergunta: {pergunta_ant}")
            historico_parts.append(f"Resposta: {resposta_ant[:200]}...")
            historico_parts.append("")
        
        historico_parts.append("---")
        return "\n".join(historico_parts)
    
    def _adicionar_memoria(self, usuario_id: str, pergunta: str, resposta: str):
        """Adiciona interaÃ§Ã£o Ã  memÃ³ria de conversas"""
        if usuario_id not in self.memoria_conversas:
            self.memoria_conversas[usuario_id] = []
        
        self.memoria_conversas[usuario_id].append((pergunta, resposta))
        
        # Manter apenas Ãºltimas 10 interaÃ§Ãµes por usuÃ¡rio
        if len(self.memoria_conversas[usuario_id]) > 10:
            self.memoria_conversas[usuario_id] = self.memoria_conversas[usuario_id][-10:]

    def processar_pergunta(self, pergunta: str, user_profile: dict) -> str:
        """MÃ©todo sÃ­ncrono de compatibilidade para o sistema hierÃ¡rquico"""
        import asyncio
        try:
            # Criar e executar loop de eventos se necessÃ¡rio
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # JÃ¡ existe um loop rodando, criar uma nova tarefa
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(
                            asyncio.run,
                            self.processar_async(pergunta, user_profile)
                        )
                        return future.result()
                else:
                    return loop.run_until_complete(self.processar_async(pergunta, user_profile))
            except RuntimeError:
                # NÃ£o hÃ¡ loop de eventos, criar um novo
                return asyncio.run(self.processar_async(pergunta, user_profile))
        except Exception as e:
            print(f"âŒ Erro no mÃ©todo de compatibilidade: {e}")
            return "Desculpe, encontrei um erro ao processar sua pergunta sobre suporte. Por favor, tente novamente."


def criar_agente_enduser_async(*, debug: bool = False) -> AgenteEndUserAsync:
    """Factory function para criar o agente de Suporte ao UsuÃ¡rio Final assÃ­ncrono"""
    return AgenteEndUserAsync(debug=debug)


if __name__ == "__main__":
    import asyncio
    
    async def test_agente_enduser_async():
        agente = criar_agente_enduser_async(debug=True)
        
        perfil_demo = {
            "Nome": "Fulano de Tal",
            "Cargo": "Analista",
            "Departamento": "Geral",
            "nivel_hierarquico": 2,
            "geografia": "BR",
            "projetos": ["N/A"],
        }

        perguntas_demo = [
            "Como resetar minha senha do sistema?",
            "Como usar o Teams para reuniÃµes?",
        ]

        for pergunta in perguntas_demo:
            print(f"\nâ“ Pergunta: {pergunta}")
            resposta = await agente.processar_async(pergunta, perfil_demo)
            print(f"ğŸ¤– Marina: {resposta}")
            print("-" * 80)
    
    asyncio.run(test_agente_enduser_async())